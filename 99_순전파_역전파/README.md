# 순전파와 역전파
다층 퍼셉트론(Multi-layer Perceptron, MLP)으로 학습 한다는 것은 최종 출력값과 실제값의 오차가 최소화 되도록 가중치와 편향을 계산하여 결정하는 것이다.

순전파 (Feedforward) 알고리즘 에서 발생한 오차를 줄이기 위해 새로운 가중치를 업데이트하고, 새로운 가중치로 다시 학습하는 과정을 역전파 (Backpropagation) 알고리즘 이라고 한다.

이러한 역전파 학습을 오차가0에 가까워 질 때까지 반복한다. 역전파 알고리즘을 실행할때 가중치를 결정하는 방법에서는 경사하강법이 사용된다.

* 경사하강법은 이후 강의에서 설명한다.

## 순전파 (Feedfoward)

입력층에서 은닉층 방향으로 이동하면서 각 입력에 해당하는 가중치가 곱해지고, 결과적으로 가중치 합으로 계산되어 은닉층 뉴런의 함수 값이 입력되며, 각 층마다 반복되다가 출력층에서 최종 결과가 출력된다.



## 역전파 (Backpropagation)

순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 갱신한다.

즉 W(가중치)의 적절한 값을 찾는과정이 역전파 과정이다.

출력값과 실제값의 차이인 Loss를 줄이는 것이 신경망 학습의 목적인데, 입력값은 이미 정해져있기 때문에 입력값에 곱해지는 W값에 변화를 주는 것으로 출력값을 조절한다.

W를 갱신하기 위해서는 손실함수의 방향, 즉 기울기가 필요하며, 이는 수치 미분과, 오차역전파법을 이용하여 구할 수 있다.

기울기를 구한다음에야 W를 갱신하는데, 이 과정은 매개변수 갱신이라 하며, SGD, Adagrad, Adam, Momentum 등의 방법으로 갱신한다.

## 신경망 학습 순서

1. 
